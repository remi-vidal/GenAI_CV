import logging
import os
import re
import io
import json
import time
import streamlit as st
import shutil
import google.generativeai as genai
import google.api_core.exceptions
import pandas as pd
import extract_msg
from google.generativeai.types import GenerationConfig
from utils import getResume, anonymize_cv, extract_linkedin_infos, extract_text_from_pdf
# from utils import *

# from dotenv import load_dotenv
# load_dotenv()  ## load all our environment variables
# genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
# PASSWORD = os.getenv("PASSWORD")


api_key = st.secrets["GOOGLE_API_KEY"]
genai.configure(api_key=api_key)
PASSWORD = st.secrets["PASSWORD"]



def get_gemini_response(input_text, max_retries=5, base_wait=30):
    """
    G√©n√®re une r√©ponse en g√©rant les erreurs de quota (429).

    Args:
        input_text (str): Texte d'entr√©e pour le mod√®le.
        max_retries (int): Nombre maximum de tentatives avant d'abandonner.
        base_wait (int): Temps d'attente initial (en secondes) avant le premier retry.

    Returns:
        dict: La r√©ponse du mod√®le sous forme de JSON.
    """
    model = genai.GenerativeModel("gemini-1.5-flash")

    for attempt in range(max_retries):
        try:
            response = model.generate_content(
                input_text,
                generation_config=GenerationConfig(response_mime_type="application/json"),
            )
            return json.loads(response.text)  # Retourne la r√©ponse si tout va bien

        except google.api_core.exceptions.ResourceExhausted:
            wait_time = base_wait * (2 ** attempt)  # Exponentiel : 30s, 60s, 120s, 240s...
            st.warning(f"Quota d√©pass√©. Tentative {attempt + 1}/{max_retries}. R√©essai dans {wait_time} secondes...")
            time.sleep(wait_time)
            st.empty()

        except Exception as e:
            st.error(f"Erreur inattendue : {e}")
            return {"Ann√©e de diplomation": "N/A", "Comp√©tences": "N/A"}  # Valeurs par d√©faut en cas d'erreur fatale

    st.error("√âchec apr√®s plusieurs tentatives. Veuillez r√©essayer plus tard.")
    return {"Ann√©e de diplomation": "N/A", "Comp√©tences": "N/A"}  # Valeurs par d√©faut si toutes les tentatives √©chouent

## Streamlit app
st.set_page_config(layout="wide")  # Wide mode by default
st.title("ATS")

if "authenticated" not in st.session_state:
    st.session_state["authenticated"] = False

def login():
    st.title("üîê Connexion")
    password_input = st.text_input("Mot de passe :", type="password")

    if st.button("Se connecter"):
        if password_input == PASSWORD:
            st.success("‚úÖ Acc√®s autoris√© !")
            st.session_state["authenticated"] = True
            st.rerun()
        else:
            st.error("Mot de passe incorrect.")

if not st.session_state["authenticated"]:
    login()
else:



    # Prompt Template
    input_prompt = """
    Tu joues le r√¥le d'un recruteur data qui doit extraire des informations cl√©s d'un CV.
    Un(e) candidat(e) a envoy√© son CV par mail.

    Retrouve l'ann√©e de diplomation et les 5 comp√©tences techniques data cl√©s dans le CV ci-dessous.
    J'ai √©galement besoin de savoir si le candidat est freelance ou non.

    Pour l'ann√©e, fais attention car parfois une formation est sp√©cifi√©e avec les dates de d√©but et de fin.
    Par exemple : 09/2022 - 06/2024 ou bien 2021 √† 2022. Dans ces cas-l√†, il faut aller chercher l'ann√©e de fin, c'est-√†-dire
    respectivement 2024 et 2022. De plus il peut y avoir plusieurs dipl√¥mes, dans ce cas, il faut prendre le plus r√©cent.


    CV: {text}

    Je veux une r√©ponse en un seul string ayant la structure suivante :
    {{"Freelance" : "OUI/NON", "Ann√©e de diplomation": "YYYY", "Comp√©tences": "comp√©tence1, comp√©tence2, comp√©tence3, comp√©tence4, comp√©tence5"}}
    """


    # Upload files via drag-and-drop
    uploaded_files = st.file_uploader(
        "Glissez-d√©posez vos fichiers .msg ici :", 
        type=["msg"], 
        accept_multiple_files=True
    )

    if uploaded_files:

        cvs_folder = "CVs"
        all_responses = []
        batch_size = 15  # Nombre max de requ√™tes par minute

        # Get the list of all .msg files
        total_mails = len(uploaded_files)
        processed_mails = 0

        # Initialize progress bar
        progress_bar = st.progress(0)
        progress_text = st.empty()
        pause_text = st.empty()

        # Batch processing .msg files

        for i in range(0, total_mails, batch_size):
            batch_files = uploaded_files[i:i + batch_size]

            for file in batch_files:
                filename = file.name
                print(f"Processing: {filename}")

                # Extraire le job depuis le nom de l'email
                match = re.search(r'application_ (.*?) from', filename)
                job_name = match.group(1) if match else "Inconnu"

                # Extract names from the email
                email_name = filename.split("from")[1].split(".msg")[0] if "from" in filename else "Inconnu"
                noms_from_email = email_name.split()
                print("Noms de l'email :", noms_from_email)

                # Lecture du fichier .msg directement depuis l'upload
                msg_bytes = file.read()
                msg = extract_msg.Message(io.BytesIO(msg_bytes))

                # Extract the date from the email
                date_envoi = msg.date.strftime("%Y-%m-%d")

                # Extract LinkedIn title and LinkedIn address
                title, address = extract_linkedin_infos(msg)
                

                # Resume extraction
                final_path = getResume(msg, cvs_folder)

                if not final_path : #Notamment si c'est un word
                    logging.error(f"Skipping email {filename}, no valid CV found.")
                    response_data = {"Ann√©e de diplomation": "N/A", "Comp√©tences": "N/A"}

                    all_responses.append(
                        {
                            "Job": job_name,
                            "Date": date_envoi,
                            "Mail": "N/A",
                            "Nom": " ".join(noms_from_email),
                            "Titre LInkedIn": title,
                            "Adresse": address,
                            "Freelance": "N/A",
                            "Dipl√¥me": "N/A",
                            "Comp√©tences Tech": "N/A",
                        }
                    )
                else:  # If a file has been successfully saved
                    text_cv = extract_text_from_pdf(final_path)

                    # Anonymization
                    text_anonymise, extracted_email = anonymize_cv(text_cv, [name for name in noms_from_email if len(name) > 2])

                    if text_anonymise == "":
                        all_responses.append(
                            {
                                "Job": job_name,
                                "Date": date_envoi,
                                "Mail": "N/A",
                                "Nom": " ".join(noms_from_email),
                                "Titre LInkedIn": title,
                                "Adresse": address,
                                "Freelance": "N/A",
                                "Dipl√¥me": "N/A",
                                "Comp√©tences Tech": "N/A",
                            }
                        )

                    # print("Texte anonymis√© :", text_anonymise)
                    # print("Email extrait :", extracted_email)

                    else:
                        # Si le CV a du contenu, on le fournit au LLM
                        formatted_prompt = input_prompt.format(text=text_anonymise)
                        response = get_gemini_response(formatted_prompt)
                        print("R√©ponse : ", response)

                        all_responses.append(
                            {   
                                "Job": job_name,
                                "Date": date_envoi,
                                "Mail": extracted_email,
                                "Nom": " ".join(noms_from_email),
                                "Titre LInkedIn": title,
                                "Adresse": address,
                                "Freelance": response["Freelance"],
                                "Dipl√¥me": response["Ann√©e de diplomation"],
                                "Comp√©tences Tech": response["Comp√©tences"],
                            }
                        )  # On retourne le texte anonymis√© + l'email et le nom extraits

                # Update progress
                processed_mails += 1
                progress_bar.progress(processed_mails / total_mails)
                progress_text.text(f"{processed_mails} mails trait√©s sur {total_mails}")

            if i + batch_size < total_mails:
                pause_text.text("Pause de 1 minute pour respecter le quota de l'API...")
                time.sleep(60)
                pause_text.empty()  # Clear the pause message after the pause

        # Create a DataFrame
        df = pd.DataFrame(all_responses)
        df = df.sort_values(by="Job").reset_index(drop=True)

        # Fonction de mise en forme
        def highlight_rows(row):
            color = ""
            if str(row["Dipl√¥me"]).isdigit() and int(row["Dipl√¥me"]) <= 2020:
                color = "background-color: lightgreen"
            if row["Freelance"] == "OUI":
                color = "background-color: lightblue"
            return [color] * len(row)

        # Appliquer le style
        styled_df = df.style.apply(highlight_rows, axis=1)

        # Afficher dans Streamlit
        st.dataframe(styled_df)


        if os.path.exists(cvs_folder):
            shutil.rmtree(cvs_folder)  # Remove folder and its content
            os.makedirs(cvs_folder)  # Recreate folder if another script needs it
